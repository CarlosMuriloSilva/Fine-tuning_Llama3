{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2633,"status":"ok","timestamp":1748052858034,"user":{"displayName":"Carlos Murilo","userId":"11195928426501929705"},"user_tz":180},"id":"rszAxEbZOA43","outputId":"ff8eae81-d524-427c-9390-9e693095a634"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"cQgaM80e8ATp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748052872432,"user_tz":180,"elapsed":5862,"user":{"displayName":"Carlos Murilo","userId":"11195928426501929705"}},"outputId":"2c99ad87-cef2-40bd-a413-fc0e947484f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: unsloth 2025.5.7 does not provide the extra 'torch'\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["# 1. Instalação de pacotes\n","!pip install -U \"unsloth[torch]\" -q\n","!pip install \"transformers==4.51.3\" \"datasets\" \"peft\" \"trl\" \"bitsandbytes\" accelerate -q"]},{"cell_type":"code","source":["# 2. Importações principais\n","from unsloth import FastLanguageModel\n","from datasets import load_dataset\n","from transformers import TrainingArguments, DataCollatorForLanguageModeling\n","import torch\n","\n","# 3. Carrega modelo 4-bit + tokenizer\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n","    max_seq_length = 2048,\n","    dtype = torch.float16,\n","    load_in_4bit = True,\n",")\n","\n","# 4. Aplica LoRA para permitir treino\n","model = FastLanguageModel.get_peft_model(\n","    model,\n","    r=16,\n","    lora_alpha=32,\n","    lora_dropout=0.05,\n","    bias=\"none\",\n",")\n","\n","# 5. Carrega o dataset no formato jsonl\n","# O arquivo deve ter linhas como:\n","# {\"text\": \"Gere uma descrição para o produto: Tênis XYZ\\nDescrição: Tênis de corrida com...\"}\n","dataset = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/Colab Notebooks/Fine_Tuning_Amazon_Titles_v3/dados/trn_Amazon_titles.jsonl\")[\"train\"]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6TQhSasZ-Vws","executionInfo":{"status":"ok","timestamp":1748053058969,"user_tz":180,"elapsed":15441,"user":{"displayName":"Carlos Murilo","userId":"11195928426501929705"}},"outputId":"1553b82b-3281-49b7-86e0-f0195f4131b6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2025.5.7: Fast Llama patching. Transformers: 4.51.3.\n","   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.3.0\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"stream","name":"stderr","text":["Unsloth 2025.5.7 patched 32 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"]}]},{"cell_type":"code","source":["# 6. Tokeniza o dataset manualmente\n","def tokenize(example):\n","    return tokenizer(\n","        example[\"text\"],\n","        truncation=True,\n","        padding=False,\n","        max_length=2048,\n","    )\n","\n","tokenized_dataset = dataset.map(tokenize, batched=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["25d155c593fc4ae691c5819dfce4f420","5f4c4d61727f40288d51b1d66249112c","f9a13c2cfc104966a705e892ec9e250f","e5eea99f41614f74bed0f4467f0a5c03","12947d3445014bcd8dbbcbdc9de0e826","e3af0c8d11e14bb89bdfa38b2647fc81","956ae503cb3943218155195c677fdad7","7f0b80216d0c4dbf9dbce3f0408c2bb7","ae98fb6c4057466dab3c991471e9342c","133440c53228439fbd6b6ab6a3df029f","04ecf2e92e374dcc81d8e7026d1b4a02"]},"id":"YdXWh1vkANbC","executionInfo":{"status":"ok","timestamp":1748053119788,"user_tz":180,"elapsed":26800,"user":{"displayName":"Carlos Murilo","userId":"11195928426501929705"}},"outputId":"f17e08c1-5e6c-456d-8457-7b979ce99474"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/210551 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25d155c593fc4ae691c5819dfce4f420"}},"metadata":{}}]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1748053158127,"user":{"displayName":"Carlos Murilo","userId":"11195928426501929705"},"user_tz":180},"id":"x34scJx7VTxP"},"outputs":[],"source":["# 7. Data collator para linguagem causal (sem masked language model)\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer,\n","    mlm=False,\n",")"]},{"cell_type":"code","source":["# 8. Argumentos do treinamento\n","training_args = TrainingArguments(\n","    output_dir=\"modelo_lora_final\",\n","    per_device_train_batch_size=2,\n","    gradient_accumulation_steps=4,\n","    warmup_steps=20,\n","    max_steps=300,  # Ajuste conforme o tamanho do seu dataset\n","    learning_rate=2e-4,\n","    fp16=True,\n","    logging_steps=10,\n","    save_steps=100,\n","    save_total_limit=2,\n","    report_to=\"none\"\n",")"],"metadata":{"id":"jNr-vL_77MNo","executionInfo":{"status":"ok","timestamp":1748053163111,"user_tz":180,"elapsed":22,"user":{"displayName":"Carlos Murilo","userId":"11195928426501929705"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["from transformers import Trainer\n","\n","# 9. Treina o modelo\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_dataset,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n",")\n","\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"agVA8oqKBbe1","executionInfo":{"status":"ok","timestamp":1748054299337,"user_tz":180,"elapsed":1017440,"user":{"displayName":"Carlos Murilo","userId":"11195928426501929705"}},"outputId":"fd3c4f84-2741-45f8-e0fe-64479c4dc91f"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-10-84d49e793c06>:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n","==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n","   \\\\   /|    Num examples = 210,551 | Num Epochs = 1 | Total steps = 300\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n","\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n"," \"-____-\"     Trainable parameters = 41,943,040/8,000,000,000 (0.52% trained)\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Will smartly offload gradients to save VRAM!\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 16:48, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>2.634300</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>2.166000</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>2.215800</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>2.142200</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>2.147500</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>2.256900</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>2.184400</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>2.130400</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>2.153600</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>2.105000</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>2.184300</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>2.094300</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>2.202300</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>2.063500</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>2.194300</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>2.294700</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>2.146700</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>2.172800</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>2.253400</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>2.084900</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>2.204300</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>2.368200</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>2.051600</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>2.004100</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>2.114200</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>2.080100</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>2.176900</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>2.188000</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>2.156700</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>2.163900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=300, training_loss=2.1778425470987957, metrics={'train_runtime': 1015.1519, 'train_samples_per_second': 2.364, 'train_steps_per_second': 0.296, 'total_flos': 2.095505551373107e+16, 'train_loss': 2.1778425470987957, 'epoch': 0.011398609369656901})"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# 10. Salva o modelo treinado\n","model.save_pretrained(\"modelo_lora_final\")\n","tokenizer.save_pretrained(\"modelo_lora_final\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oEYi7cX-A1VH","executionInfo":{"status":"ok","timestamp":1748055332655,"user_tz":180,"elapsed":1181,"user":{"displayName":"Carlos Murilo","userId":"11195928426501929705"}},"outputId":"90b666c2-51b0-4c19-fad4-3324e65848e3"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('modelo_lora_final/tokenizer_config.json',\n"," 'modelo_lora_final/special_tokens_map.json',\n"," 'modelo_lora_final/tokenizer.json')"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["output_directory = \"/content/drive/MyDrive/Colab Notebooks/Fine_Tuning_Amazon_Titles_v3/modelo_lora_final\" # Substitua pelo seu caminho real\n","model.save_pretrained(output_directory)\n","tokenizer.save_pretrained(output_directory)"],"metadata":{"id":"dNGvWQwjOUvn","executionInfo":{"status":"ok","timestamp":1748055459204,"user_tz":180,"elapsed":1318,"user":{"displayName":"Carlos Murilo","userId":"11195928426501929705"}},"outputId":"99ffc255-5943-46b4-f011-3f90ea911b28","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('/content/drive/MyDrive/Colab Notebooks/Fine_Tuning_Amazon_Titles_v3/modelo_lora_final/tokenizer_config.json',\n"," '/content/drive/MyDrive/Colab Notebooks/Fine_Tuning_Amazon_Titles_v3/modelo_lora_final/special_tokens_map.json',\n"," '/content/drive/MyDrive/Colab Notebooks/Fine_Tuning_Amazon_Titles_v3/modelo_lora_final/tokenizer.json')"]},"metadata":{},"execution_count":13}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[{"file_id":"https://github.com/enricoferraz/fine-tuning-rag-documentos-fiap/blob/main/Aula%2002%20-%20Fine%20tuning%20de%20LLM%20para%20documentos/finetuning_summarizer.ipynb","timestamp":1719586601685}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"25d155c593fc4ae691c5819dfce4f420":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5f4c4d61727f40288d51b1d66249112c","IPY_MODEL_f9a13c2cfc104966a705e892ec9e250f","IPY_MODEL_e5eea99f41614f74bed0f4467f0a5c03"],"layout":"IPY_MODEL_12947d3445014bcd8dbbcbdc9de0e826"}},"5f4c4d61727f40288d51b1d66249112c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3af0c8d11e14bb89bdfa38b2647fc81","placeholder":"​","style":"IPY_MODEL_956ae503cb3943218155195c677fdad7","value":"Map: 100%"}},"f9a13c2cfc104966a705e892ec9e250f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f0b80216d0c4dbf9dbce3f0408c2bb7","max":210551,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae98fb6c4057466dab3c991471e9342c","value":210551}},"e5eea99f41614f74bed0f4467f0a5c03":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_133440c53228439fbd6b6ab6a3df029f","placeholder":"​","style":"IPY_MODEL_04ecf2e92e374dcc81d8e7026d1b4a02","value":" 210551/210551 [00:26&lt;00:00, 7407.86 examples/s]"}},"12947d3445014bcd8dbbcbdc9de0e826":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3af0c8d11e14bb89bdfa38b2647fc81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"956ae503cb3943218155195c677fdad7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f0b80216d0c4dbf9dbce3f0408c2bb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae98fb6c4057466dab3c991471e9342c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"133440c53228439fbd6b6ab6a3df029f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04ecf2e92e374dcc81d8e7026d1b4a02":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}